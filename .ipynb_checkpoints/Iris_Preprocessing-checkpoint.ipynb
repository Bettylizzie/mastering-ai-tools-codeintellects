{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a2600c5",
   "metadata": {},
   "source": [
    "# Iris Dataset - Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed79617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c307253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"Iris (1).csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa9d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Drop the 'Id' column\n",
    "df.drop(\"Id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845f883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Check for duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a32efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Encode the target column ('Species')\n",
    "le = LabelEncoder()\n",
    "df['Species'] = le.fit_transform(df['Species'])  # 0=setosa, 1=versicolor, 2=virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bd08fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Split into features and target\n",
    "X = df.drop('Species', axis=1)\n",
    "y = df['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f03288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca91c0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Show shapes\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
